# ============================================
# Dockerfile for Django + Ollama (AI Agent)
# ============================================
# This Dockerfile creates a container that runs both:
# 1. Django backend (gunicorn)
# 2. Ollama LLM server (phi-3-mini model)
#
# For Render Starter Plan: 2 CPU, 8GB RAM
# ============================================

FROM python:3.11-slim

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV OLLAMA_HOST=0.0.0.0:11434
ENV OLLAMA_MODELS=/app/ollama_models

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    # WeasyPrint dependencies
    libpango-1.0-0 \
    libpangoft2-1.0-0 \
    libpangocairo-1.0-0 \
    # Ollama dependencies
    curl \
    ca-certificates \
    # Process management
    supervisor \
    # Cleanup
    && rm -rf /var/lib/apt/lists/*

# Install Ollama
RUN curl -fsSL https://ollama.com/install.sh | sh

# Create directory for Ollama models
RUN mkdir -p /app/ollama_models

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Install additional AI dependencies
RUN pip install --no-cache-dir httpx aiohttp

# Copy the rest of the application
COPY . .

# Create supervisor configuration
RUN mkdir -p /etc/supervisor/conf.d
COPY supervisord.conf /etc/supervisor/conf.d/supervisord.conf

# Create startup script
COPY start.sh /app/start.sh
RUN chmod +x /app/start.sh

# Collect static files
RUN python manage.py collectstatic --noinput

# Expose ports
EXPOSE $PORT
EXPOSE 11434

# Start supervisor (manages both Django and Ollama)
CMD ["/app/start.sh"]
